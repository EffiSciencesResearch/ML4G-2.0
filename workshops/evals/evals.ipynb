{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a href=\"https://colab.research.google.com/github/EffiSciencesResearch/ML4G-2.0/blob/master/workshops/evals/evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
                "# Evals\n",
                "\n",
                "## Contents\n",
                "\n",
                "- \n",
                "- \n",
                "..\n",
                "\n",
                "## Goals\n",
                "\n",
                "- Get experience using Inspect, the open source evals framework from UK AI Safety Institute.\n",
                "- Get experience conducting evals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "Replace `your-openai-api-key` with an actual openai api key."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    import google.colab\n",
                "\n",
                "    IN_COLAB = True\n",
                "except:\n",
                "    IN_COLAB = False\n",
                "\n",
                "if IN_COLAB:\n",
                "    # Install packages\n",
                "    %pip install inspect-ai openai\n",
                "else:\n",
                "    !pip install inspect-ai openai"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"OPENAI_API_KEY\"] = ()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from inspect_ai import Task, task, eval\n",
                "from inspect_ai.dataset import example_dataset\n",
                "from inspect_ai.scorer import model_graded_fact\n",
                "from inspect_ai.solver import chain_of_thought, generate, self_critique"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = example_dataset(\"theory_of_mind\")\n",
                "\n",
                "sample = dataset[0]\n",
                "\n",
                "sample.input\n",
                "\n",
                "print(sample.input[0].content)\n",
                "\n",
                "print(sample.target)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "solvers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scorer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@task\n",
                "def theory_of_mind():\n",
                "    return Task(\n",
                "        dataset=dataset[0:3],\n",
                "        plan=[\n",
                "            # chain_of_thought(),\n",
                "            generate(),\n",
                "            # self_critique()\n",
                "        ],\n",
                "        scorer=None,\n",
                "        # scorer=model_graded_fact(),\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "logs = eval(\n",
                "    [theory_of_mind()],\n",
                "    model=\"openai/gpt-4o-mini\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "samples = logs[0].samples\n",
                "sample = samples[0]\n",
                "sample.messages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python",
            "pygments_lexer": "ipython3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
